---
title: "Introduction to Fused ANCOVA with 2 modalities"
author: "Marie Perrot-Dock√®s, Julien Chiquet"
date: "16 avril 2018"
output:
  md_document:
    variant: markdown_github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Install and load the package

```{r}
devtools::install_github("Marie-PerrotDockes/Fus2mod")
require(Fus2mod)

```

## Dataset Simulation

We start by generate a toy exemple, where we have two modalities H and I, 10 regressors and 30 individuals. For now we only have one response. 
We generate our dataset such that the 3 first regressors have no effect on the response , then the regressors 4, 5 and 6 have an effect on the response onl y on the sample that comes from the modality I and the regressors 7 and 8 have an effect on the response for the modality N but not for the modlity I.

```{r}
n <- 40
p <- 10
K <- 2
q <- 1


# B <- Simul_B(p, q, s, f, k)
B <- c(0, 0,
       0, 0,
       0, 0,
       0, 0,
       0, 3,
       0, 2.5,
       0, 2,
       2.2, 0,
       1.8, 0,
       2, 2,
       2, 2
       )

group <- c(rep("H", n / 2), rep("I", n / 2))
K <- nlevels(as.factor(group))
regressors     <- matrix(rnorm(n * p), ncol = (length(B) / K - 1))

X             <- model.matrix(~group + group:regressors - 1)
y <- as.matrix(X %*% B + matrix(rnorm(n * q ), ncol = q))

y <- scale(y)

```

## Model Selection

Here we foccus on the model $Y=XB+E$, where $Y$, $B$ and $E$ are vector and $X$ is a one-way ANCOVA design matrix. We have two objectifs : we want to find which collumns of $X$ can explain the response $y$ in the first hand. In the second hand we want to observe if the differents modalities influence the values of the coefficient of the regressors on the response, in other terms if the collumn group1:regressorsi will have the same coefficient than the collum group2:regressorsi. 
To do that we propose to apply a lasso criterion to the model : $Y=X_2B+E$ where $X2$ is the concatenation of $X$ and the matrix of the regressors. To be abble to arrange the level of fusion we propose to put weight on the penalties a weight $b$ if the coefficients is the coefficient of a couple regressors modalities and a weight $a$ if the coefficients is the coefficients of a whole regressors. Like $2pb+pa$ must be equal to $3p+2$ fixing $a$ will give us a value of $b$. Thus, the more $a$ is small the more the model will encourage the coefficient of two different modalities for the same regressors to be the same. 
For more detail about this model we confer the reader to the file "2_modalities.pdf".

We first propose a Cross-validation step. For different values of $a$  we will apply a 5-fold CV on our data and keep the minimal error (cvm)and the degree of freedom (ddl) that match this minimal error. We will do that $nrep =10$ times  for each value of $a$ the mean on this 10 replicats  are display bellow.

```{r}
 CV <- cv.fl2(response = y, regressors = regressors, group = group, mina = 0.1, nfold = 5, nrep= 10,
                   nb.cores = 3, plot = TRUE)
```

By watching this plot we propose to take the $a$ that minimise the degree of freedom because it is the lower (or really close to ) the lower error of prediction.


```{r}
ddl <- CV[CV$Criterion =="ddl", ]
a <- ddl[which.min(ddl$mean), "a"]
a
```

If we want we can add a stability selection step to keep the more stable variable. 
In order to avoid that sometimes the model select as non null value the coefficient of the whole regressors and sometimes it keep it only for one modality we perform the fusion before the stability selection and then apply the stability selection step.

```{r}
source('~/Documents/Multivar_selec/Multivar_selec/FusedLasso/Fus2mod/R/stab.fl2_fixa.R', echo=TRUE)
stab <- stab.fl2_fixa(response = y, regressors, group, a,
                   lambda = NULL,  nrep= 1000,
                   nb.cores = 3, plot = TRUE)
stab
```

```{r}
par(mf.row=c(1,2))
plot(stab, type="maxsel", main="Maximum selection frequencies")
plot(stab, type="path", main="Stability paths")
```
```{r}
sel <-names(stabsel(stab, cutoff=0.8)$selected)[-c(1,2)]
sel 
```

```{r}
names(B) <- colnames(X)

B_long <- c(0, 0,
       0, 0,
       0, 0,
       0, 0,
       0, 1.4,
       0, 1.5,
       0, 2,
       1.2, 0,
       1.8, 0,
       0, 0,
       0, 0, 
       rep(0 ,8),1,1
       )
colnames(regressors) <- paste0('regressors', 1:p)
names(B_long) <- c(colnames(X), colnames(regressors))
names(B_long[B_long != 0])
```
 
If we take a threshold of 0.8, we have a True Positive Rate equal to `r round(sum(sel %in% names(B_long[B_long!=0])) / sum(as.numeric(B_long)!=0),2)` and a False Positive Rate equal to `r round(sum(sel %in% names(B_long[B_long==0])) / sum(as.numeric(B_long)==0),2)`.
